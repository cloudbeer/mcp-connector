"""
MCP client wrapper for maintaining active contexts.
"""
import logging
from typing import List, Any, Dict, Optional
from strands import Agent

from app.config import settings

logger = logging.getLogger(__name__)


class MCPAgentWrapper:
    """
    包装 MCP 客户端和 Agent，确保在使用 Agent 时客户端上下文始终是活跃的。
    
    这个类维护一个持久的客户端上下文，并提供方法来安全地使用 Agent。
    """
    
    def __init__(self, clients: List[Any], tools: List[Any]):
        """
        初始化 MCP Agent 包装器。
        
        Args:
            clients: MCP 客户端列表
            tools: 工具列表
        """
        self.clients = clients
        self.tools = tools
        self.agent = None
        self.active_contexts = []
        self.is_initialized = False
        logger.info(f"Created MCPAgentWrapper with {len(clients)} clients and {len(tools)} tools")
    
    def initialize(self) -> bool:
        """
        初始化包装器，进入所有客户端的上下文并创建 Agent。
        
        Returns:
            bool: 是否成功初始化
        """
        if self.is_initialized:
            logger.warning("MCPAgentWrapper is already initialized")
            return True
        
        try:
            # 进入所有客户端的上下文
            self.active_contexts = []
            for client in self.clients:
                try:
                    client.__enter__()
                    self.active_contexts.append(client)
                    logger.debug(f"Entered context for client {client}")
                except Exception as e:
                    logger.error(f"Error entering client context: {e}")
                    # 如果有任何客户端上下文创建失败，关闭已创建的上下文
                    self._cleanup_contexts()
                    return False
            
            # Create model based on environment variables
            model = self._create_model_from_env()
            
            # Log model configuration details
            if model:
                model_type = model.__class__.__name__
                model_id = getattr(model, 'model_id', 'unknown')
                logger.info(f"Creating Agent with model provider: {model_type}, model ID: {model_id}")
                
                # Log additional model parameters if available
                params = {}
                if hasattr(model, 'params'):
                    params = model.params
                elif hasattr(model, 'temperature'):
                    params['temperature'] = model.temperature
                if params:
                    logger.info(f"Model parameters: {params}")
            else:
                logger.warning("No model provider configured, using default model")
            
            # 创建 Agent with model
            self.agent = Agent(tools=self.tools, model=model)
            self.is_initialized = True
            logger.info("MCPAgentWrapper initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Error initializing MCPAgentWrapper: {e}")
            self._cleanup_contexts()
            return False
    
    def _cleanup_contexts(self):
        """清理所有活跃的上下文。"""
        for client in reversed(self.active_contexts):
            try:
                client.__exit__(None, None, None)
                logger.debug(f"Exited context for client {client}")
            except Exception as e:
                logger.error(f"Error exiting client context: {e}")
        
        self.active_contexts = []
        self.is_initialized = False
    
    def close(self):
        """关闭包装器，退出所有客户端的上下文。"""
        if self.is_initialized:
            self._cleanup_contexts()
            logger.info("MCPAgentWrapper closed")
    
    def invoke(self, prompt: str) -> str:
        """
        调用 Agent 处理提示。
        
        Args:
            prompt: 提示文本
            
        Returns:
            str: Agent 的响应
            
        Raises:
            RuntimeError: 如果包装器未初始化
        """
        if not self.is_initialized:
            if not self.initialize():
                raise RuntimeError("Failed to initialize MCPAgentWrapper")
        
        try:
            # 调用 Agent
            response = self.agent(prompt)
            return str(response)
        except Exception as e:
            logger.error(f"Error invoking agent: {e}")
            # 如果调用失败，尝试重新初始化
            self._cleanup_contexts()
            if not self.initialize():
                raise RuntimeError("Failed to reinitialize MCPAgentWrapper")
            # 重试一次
            response = self.agent(prompt)
            return str(response)
    
    async def stream_async(self, prompt: str):
        """
        异步流式调用 Agent 处理提示。
        
        Args:
            prompt: 提示文本
            
        Yields:
            Agent 的流式响应
            
        Raises:
            RuntimeError: 如果包装器未初始化
        """
        if not self.is_initialized:
            if not self.initialize():
                raise RuntimeError("Failed to initialize MCPAgentWrapper")
        
        try:
            # 流式调用 Agent
            async for event in self.agent.stream_async(prompt):
                yield event
        except Exception as e:
            logger.error(f"Error streaming from agent: {e}")
            # 如果调用失败，尝试重新初始化
            self._cleanup_contexts()
            if not self.initialize():
                raise RuntimeError("Failed to reinitialize MCPAgentWrapper")
            # 重试一次
            async for event in self.agent.stream_async(prompt):
                yield event
    
    def _create_model_from_env(self):
        """Create a model instance based on settings."""
        # Get model provider from settings
        model_provider = settings.model_provider.lower()
        model_name = settings.model_name
        
        try:
            if model_provider == "openai":
                # OpenAI model configuration
                from strands.models.openai import OpenAIModel
                
                api_key = settings.openai_api_key
                base_url = settings.openai_base_url
                
                if not api_key:
                    logger.warning("OPENAI_API_KEY not set, using default model")
                    return None
                
                logger.info(f"Creating OpenAI model: {model_name}")
                return OpenAIModel(
                    client_args={
                        "api_key": api_key,
                        "base_url": base_url,
                    },
                    model_id=model_name,
                    params={
                        "temperature": 0.7,  # Default temperature
                        "max_tokens": 1000,  # Default max tokens
                    }
                )
                
            elif model_provider == "anthropic":
                # Anthropic model configuration
                from strands.models.anthropic import AnthropicModel
                
                api_key = settings.anthropic_api_key
                
                if not api_key:
                    logger.warning("ANTHROPIC_API_KEY not set, using default model")
                    return None
                
                logger.info(f"Creating Anthropic model: {model_name}")
                return AnthropicModel(
                    client_args={
                        "api_key": api_key,
                    },
                    model_id=model_name,
                    params={
                        "temperature": 0.7,  # Default temperature
                        "max_tokens": 1000,  # Default max tokens
                    }
                )
                
            elif model_provider == "bedrock":
                # AWS Bedrock model configuration
                from strands.models import BedrockModel
                
                aws_access_key = settings.aws_access_key_id
                aws_secret_key = settings.aws_secret_access_key
                aws_region = settings.aws_region
                
                logger.info(f"Creating AWS Bedrock model: {model_name}")
                
                # Create client args based on available credentials
                client_args = {}
                if aws_region:
                    client_args["region_name"] = aws_region
                
                # Only add credentials if explicitly provided
                if aws_access_key and aws_secret_key:
                    client_args["aws_access_key_id"] = aws_access_key
                    client_args["aws_secret_access_key"] = aws_secret_key
                    logger.info("Using provided AWS credentials")
                else:
                    logger.info("Using default AWS credential provider chain")
                
                return BedrockModel(
                    model_id=model_name,
                    temperature=0.7,  # Default temperature
                    top_p=0.8,  # Default top_p
                    client_args=client_args
                )
                
            else:
                logger.warning(f"Unsupported model provider: {model_provider}, using default model")
                return None
                
        except ImportError as e:
            logger.warning(f"Failed to import model for provider {model_provider}: {e}")
            logger.warning("Make sure to install the required packages:")
            if model_provider == "openai":
                logger.warning("pip install 'strands-agents[openai]'")
            elif model_provider == "anthropic":
                logger.warning("pip install 'strands-agents[anthropic]'")
            elif model_provider == "bedrock":
                logger.warning("pip install 'strands-agents[bedrock]'")
            return None
            
        except Exception as e:
            logger.error(f"Error creating model for provider {model_provider}: {e}")
            return None